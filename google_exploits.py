#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 24 23:36:01 2022

@author: moi
"""

#google exploits
from selenium.common.exceptions import (ElementClickInterceptedException,
                                        StaleElementReferenceException,
                                        NoSuchElementException, 
                                        WebDriverException,
                                        TimeoutException)
from selenium.webdriver.support import expected_conditions as EC
from assistant import parse_it, scroll_to_bottom
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup as bs
from pandas_gbq import to_gbq
import pandas as pd


ignored_exceptions = (ElementClickInterceptedException,
                        StaleElementReferenceException,
                        NoSuchElementException, 
                        WebDriverException,
                        TimeoutException)
    
def google_processing_check(wait):
    #Checks for the 'Processing' modal
    try:
        wait.until(EC.visibility_of_element_located((By.ID, 'exploits-table_processing')))
    except ignored_exceptions:
        pass

def get_google_exploits(driver, wait, today):
    
    google_exploit_db = 'https://www.exploit-db.com/' 
    driver.get(google_exploit_db)
    
    google_processing_check(wait)
    
    #change show dropdown to 120
    show_xpath = '/html/body/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div[1]/div[1]/div/label/select'
    wait.until(EC.element_to_be_clickable((By.XPATH, show_xpath))).click()
    
    show120_xpath = '/html/body/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div[1]/div[1]/div/label/select/option[4]'
    wait.until(EC.element_to_be_clickable((By.XPATH, show120_xpath))).click()
    
    scroll_to_bottom(driver)
    
    total_pages = 376
        
    google_exploit_list = []
    
    for i in range(1, total_pages + 1): 
        
        google_processing_check(wait)
        
        print(i)
    
        soup = bs(driver.page_source, 'lxml') 
    
        #find all the page tables
        google_table = soup.find('table', class_ = 'table table-striped table-bordered display dataTable no-footer dtr-inline')            
    
        try:
            this_google_table = parse_it(google_table)
            #convert to dataframe and drop the first row
            this_google_table_df = pd.DataFrame(this_google_table, columns = this_google_table[0])
            this_google_table_df = this_google_table_df.drop(this_google_table_df.index[0])
            google_exploit_list.append(this_google_table_df)
        
        except:
            pass
               
        #check for processing modal                    
        google_processing_check(wait)
        
        #scroll to bottom
        scroll_to_bottom(driver)
        
        try:
            next_css = '#exploits-table_next'
            wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, next_css))).click()
        
        except ignored_exceptions:
            
            try:
                #check for processing modal
                google_processing_check(wait)
                wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'paginate_button page-item next'))).click() # id="exploits-table_next"><a href="#" aria-controls="exploits-table" data-dt-idx="9" tabindex="0" class="page-link">Next</a></li>       
            except:
                break
    
    #concatenate the list of dataframes
    google_exploits_df = pd.concat(google_exploit_list)   
    
    #convert the date column into a timestamp
    google_exploits_df['Date'] = pd.to_datetime(google_exploits_df['Date'])
    
    #remove any duplicates (if exists)
    google_exploits_df = google_exploits_df.drop_duplicates()

    #remove periods
    google_exploits_df.columns = [x.replace('.', '') for x in google_exploits_df.columns.values.tolist()]
    
    #remove parentheses
    google_exploits_df.columns = [x.replace('(', '').replace(')','') for x in google_exploits_df.columns.values.tolist()]
    
    #change out "# of" for "no_of_"
    google_exploits_df.columns = [x.replace('#', 'no') for x in google_exploits_df.columns.values.tolist()]
      
    #make columns lower case
    google_exploits_df.columns = [x.lower() for x in google_exploits_df.columns.values.tolist()]
    
    #insert underscores for spaces
    google_exploits_df.columns = [x.replace(' ', '_') for x in google_exploits_df.columns.values.tolist()]
    
    #make a local backup copy
    google_exploits_df.to_csv('backup-data/google-exploits-{}.csv'.format(today), index = False)
    
    #load to big query
    to_gbq(google_exploits_df, 
           'google_exploits.google-exploits-table', 
           project_id = 'cyber-crime-360523', 
           if_exists = 'replace')

